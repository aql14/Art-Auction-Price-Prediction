{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "df = pd.read_csv('../data/artDataset_preprocessed.csv')\n",
    "\n",
    "# Let's transform the data set into a numpy array\n",
    "data_array = df.to_numpy()\n",
    "\n",
    "# Predictors\n",
    "X = data_array[:,1:]\n",
    "\n",
    "# Target\n",
    "y = data_array[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Baseline Model: Mean Predictor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply a linear regression model with no features, i.e. it computes the mean of y on the training data, and use this value to predict y on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Model (Mean Predictor) Cross-Validation Results:\n",
      "\n",
      "R² scores for each fold: [-0.0033 -0.001  -0.0008 -0.0035 -0.0001]\n",
      "Mean R²: -0.0017 (±0.0014)\n",
      "\n",
      "RMSE for each fold: [14133.18 15068.01 11191.55  9548.71 13583.5 ]\n",
      "Mean RMSE: 12704.9895 (±2032.1394)\n",
      "\n",
      "MAE for each fold: [7348.57 6851.1  6573.82 6568.15 6568.87]\n",
      "Mean MAE: 6782.1019 (±303.4041)\n"
     ]
    }
   ],
   "source": [
    "# Implement a baseline model (mean predictor)\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "# Set up K-Fold Cross-Validation\n",
    "k_folds = 5\n",
    "cv_strategy = KFold(n_splits=k_folds, shuffle=True, random_state=17)\n",
    "\n",
    "# Initialize the baseline model (predicts the mean of y on the training set and uses it to predict y on the test set)\n",
    "baseline_model = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Perform cross-validation on the baseline model\n",
    "baseline_cv_scores_r2 = cross_val_score(baseline_model, X, y, cv=cv_strategy, scoring='r2')\n",
    "baseline_cv_scores_neg_mse = cross_val_score(baseline_model, X, y, cv=cv_strategy, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to positive MSE and then to RMSE\n",
    "baseline_cv_scores_mse = -baseline_cv_scores_neg_mse\n",
    "baseline_cv_scores_rmse = np.sqrt(baseline_cv_scores_mse)\n",
    "\n",
    "# Define MAE scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "baseline_cv_scores_mae = -cross_val_score(baseline_model, X, y, cv=cv_strategy, scoring=mae_scorer)\n",
    "\n",
    "# Print baseline cross-validation results\n",
    "print(\"\\nBaseline Model (Mean Predictor) Cross-Validation Results:\\n\")\n",
    "print(f\"R² scores for each fold: {np.round(baseline_cv_scores_r2,4)}\")\n",
    "print(f\"Mean R²: {baseline_cv_scores_r2.mean():.4f} (±{baseline_cv_scores_r2.std():.4f})\\n\")\n",
    "print(f\"RMSE for each fold: {np.round(baseline_cv_scores_rmse,2)}\")\n",
    "print(f\"Mean RMSE: {baseline_cv_scores_rmse.mean():.4f} (±{baseline_cv_scores_rmse.std():.4f})\\n\")\n",
    "print(f\"MAE for each fold: {np.round(baseline_cv_scores_mae,2)}\")\n",
    "print(f\"Mean MAE: {baseline_cv_scores_mae.mean():.4f} (±{baseline_cv_scores_mae.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that this models r2 is lightly below zero, indicating the mean‐only predictor performs worse than using the sample mean of the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Baseline Model: OLS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the scaled and non-scaled models should have the same (similar) performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OLS Model Cross-Validation Results:\n",
      "\n",
      "R² scores for each fold: [ 0.1311  0.0906  0.1352 -0.4952  0.0076]\n",
      "Mean R²: -0.0261 (±0.2390)\n",
      "\n",
      "RMSE for each fold: [13152.69 14361.98 10403.11 11655.57 13531.56]\n",
      "Mean RMSE: 12620.9816 (±1413.7850)\n",
      "\n",
      "MAE for each fold: [6234.76 5612.13 5576.47 6764.39 5876.08]\n",
      "Mean MAE: 6012.7639 (±443.5692)\n"
     ]
    }
   ],
   "source": [
    "# Implement OLS baseline model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OLS model\n",
    "ols_model = LinearRegression()\n",
    "\n",
    "# Use the same K-Fold Cross-Validation\n",
    "k_folds = 5\n",
    "cv_strategy = KFold(n_splits=k_folds, shuffle=True, random_state=17)\n",
    "\n",
    "# Perform cross-validation on the OLS model\n",
    "ols_cv_scores_r2 = cross_val_score(ols_model, X, y, cv=cv_strategy, scoring='r2')\n",
    "ols_cv_scores_neg_mse = cross_val_score(ols_model, X, y, cv=cv_strategy, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to positive MSE and then to RMSE\n",
    "ols_cv_scores_mse = -ols_cv_scores_neg_mse\n",
    "ols_cv_scores_rmse = np.sqrt(ols_cv_scores_mse)\n",
    "\n",
    "# Define MAE scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "ols_cv_scores_mae = -cross_val_score(ols_model, X, y, cv=cv_strategy, scoring=mae_scorer)\n",
    "\n",
    "# Print OLS cross-validation results\n",
    "print(\"\\nOLS Model Cross-Validation Results:\\n\")\n",
    "print(f\"R² scores for each fold: {np.round(ols_cv_scores_r2,4)}\")\n",
    "print(f\"Mean R²: {ols_cv_scores_r2.mean():.4f} (±{ols_cv_scores_r2.std():.4f})\\n\")\n",
    "print(f\"RMSE for each fold: {np.round(ols_cv_scores_rmse,2)}\")\n",
    "print(f\"Mean RMSE: {ols_cv_scores_rmse.mean():.4f} (±{ols_cv_scores_rmse.std():.4f})\\n\")\n",
    "print(f\"MAE for each fold: {np.round(ols_cv_scores_mae,2)}\")\n",
    "print(f\"Mean MAE: {ols_cv_scores_mae.mean():.4f} (±{ols_cv_scores_mae.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I obtained wildly different (even astronomically large) R² and RMSE when I threw scaling into the mix. In theory, an ordinary least‐squares fit is invariant to affine rescaling of the features: if we scale every column by a constant and then un‐scale the coefficients, predictions end up exactly the same, so the R²/MAE/RMSE shouldn’t change.\n",
    "\n",
    "When we get huge negatives like –1e14 for R² or RMSE on the order of 1e11, it almost always means that your pipeline has become numerically unstable.\n",
    "\n",
    "Solution: get rid of the features with null variance or establish a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² per fold:       [ 0.05015095  0.1186294   0.09714017  0.06892772 -0.27228127]\n",
      "Mean R²:            0.0125 ± 0.1443\n",
      "RMSE per fold:      [10824.93609151 13944.87828144 10676.41969689 16841.46513121\n",
      "  7321.58466251]\n",
      "Mean RMSE:          11921.86 ± 3231.47\n"
     ]
    }
   ],
   "source": [
    "# 5-fold setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=14)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"var_thresh\", VarianceThreshold()),         # removes features with σ=0\n",
    "    (\"scaler\",    StandardScaler()),\n",
    "    (\"ols\",       LinearRegression())\n",
    "])\n",
    "\n",
    "# CV on R² and RMSE\n",
    "r2_scores      = cross_val_score(pipeline, X, y, cv=kf, scoring=\"r2\")\n",
    "neg_mse_scores = cross_val_score(pipeline, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "rmse_scores    = np.sqrt(-neg_mse_scores)\n",
    "\n",
    "print(\"R² per fold:      \", r2_scores)\n",
    "print(\"Mean R²:           \", f\"{r2_scores.mean():.4f} ± {r2_scores.std():.4f}\")\n",
    "print(\"RMSE per fold:     \", rmse_scores)\n",
    "print(\"Mean RMSE:         \", f\"{rmse_scores.mean():.2f} ± {rmse_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
