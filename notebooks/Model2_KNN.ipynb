{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "df = pd.read_csv('../data/artDataset_preprocessed.csv')\n",
    "\n",
    "# Let's transform the data set into a numpy array\n",
    "data_array = df.to_numpy()\n",
    "\n",
    "# Predictors\n",
    "X = data_array[:,1:]\n",
    "\n",
    "# Target\n",
    "y = data_array[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KNN Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors: 23 (weights='uniform', metric='manhattan')\n",
      "RMSE (CV): 11888.6821\n",
      "\n",
      "KNN Regression Cross-Validation Results:\n",
      "\n",
      "RMSE for each fold: [12549.9  13864.6   9477.36  9505.09 13712.51]\n",
      "Mean RMSE: 11982.7141 (±1956.6050)\n",
      "\n",
      "MSE for each fold: [1.57500078e+08 1.92227213e+08 8.98203000e+07 9.03467240e+07\n",
      " 1.88032875e+08]\n",
      "Mean MSE: 143585437.8250 (±45299591.2056)\n",
      "\n",
      "MAE for each fold: [5382.08 5131.74 4897.81 5666.3  5690.24]\n",
      "Mean MAE: 5353.6341 (±306.2301)\n"
     ]
    }
   ],
   "source": [
    "# 1. Define consistent CV strategy\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "# 2. Define pipeline and parameter grid\n",
    "    # Range of k values to test\n",
    "k_values = np.arange(1, 30, 2)  # odd numbers from 1 to 30 neighbors\n",
    "# Test different weighting schemes\n",
    "weight_options = ['uniform', 'distance']\n",
    "# Different metrics\n",
    "metric_options = ['euclidean', 'manhattan', 'chebyshev']\n",
    "\n",
    "param_knn = {\n",
    "    'knn__n_neighbors': k_values,\n",
    "    'knn__weights': weight_options,\n",
    "    'knn__metric': metric_options\n",
    "}\n",
    "\n",
    "# Pipeline for GridSearchCV\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"var_thresh\", VarianceThreshold()),  # Remove low-variance features\n",
    "    (\"scaler\", StandardScaler()),         # Standardize features\n",
    "    (\"knn\", KNeighborsRegressor())        # KNN Regressor\n",
    "])\n",
    "\n",
    "# 3. GridSearchCV (find the best parameters) with established CV strategy\n",
    "knn_cv = GridSearchCV(\n",
    "    estimator=knn_pipeline,\n",
    "    param_grid=param_knn,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=cv_strategy\n",
    ")\n",
    "knn_cv.fit(X, y)\n",
    "\n",
    "# Best parameters\n",
    "best_k = knn_cv.best_params_['knn__n_neighbors']\n",
    "best_weight = knn_cv.best_params_['knn__weights']\n",
    "best_metric = knn_cv.best_params_['knn__metric']\n",
    "\n",
    "# Generalization error (RMSE) from GridSearchCV\n",
    "best_rmse_knn = np.sqrt(-knn_cv.best_score_)\n",
    "\n",
    "print(f\"Best n_neighbors: {best_k} (weights='{best_weight}', metric='{best_metric}')\")\n",
    "print(f\"RMSE (CV): {best_rmse_knn:.4f}\")\n",
    "\n",
    "# 4. Evaluate best model separately using cross_val_score with same CV strategy\n",
    "best_knn_model = knn_cv.best_estimator_\n",
    "\n",
    "# Alternatively rebuild explicitly:\n",
    "best_knn_model = Pipeline([\n",
    "    (\"var_thresh\", VarianceThreshold()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsRegressor(n_neighbors=best_k, weights=best_weight))\n",
    "])\n",
    "\n",
    "# Obtain the MSE for each fold and compute averages\n",
    "mse_folds = -cross_val_score(\n",
    "    best_knn_model, X, y,\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "mean_mse_knn = mse_folds.mean()\n",
    "\n",
    "rmse_folds = np.sqrt(mse_folds)\n",
    "mean_rmse_knn = np.sqrt(mean_mse_knn)\n",
    "\n",
    "# Define MAE scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Cross-validated MAE (negated back to positive)\n",
    "mae_scores = -cross_val_score(\n",
    "    best_knn_model, X, y,\n",
    "    cv=cv_strategy,\n",
    "    scoring=mae_scorer\n",
    ")\n",
    "mean_mae_knn = mae_scores.mean()\n",
    "\n",
    "# Print detailed results\n",
    "print(\"\\nKNN Regression Cross-Validation Results:\\n\")\n",
    "\n",
    "print(f\"RMSE for each fold: {np.round(rmse_folds, 2)}\")\n",
    "print(f\"Mean RMSE: {mean_rmse_knn:.4f} (±{rmse_folds.std():.4f})\\n\")\n",
    "\n",
    "print(f\"MSE for each fold: {np.round(mse_folds, 2)}\")\n",
    "print(f\"Mean MSE: {mean_mse_knn:.4f} (±{mse_folds.std():.4f})\\n\")\n",
    "\n",
    "print(f\"MAE for each fold: {np.round(mae_scores, 2)}\")\n",
    "print(f\"Mean MAE: {mean_mae_knn:.4f} (±{mae_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are some limitations with this KNN approach, with the curse of dimensionality being the most relevant one. In high-dimensional spaces, distances become less meaningful, and the KNN algorithm becomes less effective. Because of that, it might be pertinent to perform a dimensionaity reduction. PCA will be used to reduce the number of features and integrated into the gridsearch pipeline to find the optimal number of components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KNN Regression: PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      " - n_neighbors: 7\n",
      " - weights: uniform\n",
      " - metric: euclidean\n",
      " - PCA components: 10\n",
      "RMSE (CV): 11457.67\n",
      "\n",
      "KNN Regression with PCA Cross-Validation Results:\n",
      "\n",
      "RMSE for each fold: [11519.15 12594.38  9038.03  9381.01 13978.27]\n",
      "Mean RMSE: 11457.67 (±1881.25)\n",
      "\n",
      "MSE for each fold: [1.32690769e+08 1.58618370e+08 8.16860722e+07 8.80033434e+07\n",
      " 1.95391971e+08]\n",
      "Mean MSE: 131278105.23 (±42876912.70)\n",
      "\n",
      "MAE for each fold: [5223.38 4296.16 4479.42 5049.04 5650.7 ]\n",
      "Mean MAE: 4939.74 (±494.77)\n"
     ]
    }
   ],
   "source": [
    "# 1. Define consistent CV strategy\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "# 2. Define pipeline and parameter grid\n",
    "k_values = np.arange(1, 30, 2)  # odd neighbors: 1 to 29\n",
    "metric_options = ['euclidean', 'manhattan']\n",
    "pca_components = [5, 10, 15, 20, 25]\n",
    "\n",
    "param_knn_pca = {\n",
    "    'knn__n_neighbors': k_values,\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': metric_options,\n",
    "    'pca__n_components': pca_components\n",
    "}\n",
    "\n",
    "# Pipeline for GridSearchCV\n",
    "knn_pca_pipeline = Pipeline([\n",
    "    (\"var_thresh\", VarianceThreshold()),   # Remove low-variance features\n",
    "    (\"scaler\", StandardScaler()),          # Standardize features\n",
    "    (\"pca\", PCA()),                         # PCA for dimensionality reduction\n",
    "    (\"knn\", KNeighborsRegressor())          # KNN Regressor\n",
    "])\n",
    "\n",
    "# 3. GridSearchCV (find the best parameters)\n",
    "knn_pca_cv = GridSearchCV(\n",
    "    estimator=knn_pca_pipeline,\n",
    "    param_grid=param_knn_pca,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1\n",
    ")\n",
    "knn_pca_cv.fit(X, y)\n",
    "\n",
    "# Best parameters\n",
    "best_params = knn_pca_cv.best_params_\n",
    "best_k = best_params['knn__n_neighbors']\n",
    "best_weight = best_params['knn__weights']\n",
    "best_metric = best_params['knn__metric']\n",
    "best_n_components = best_params['pca__n_components']\n",
    "\n",
    "# Generalization error (RMSE) from GridSearchCV\n",
    "best_rmse_knn_pca = np.sqrt(-knn_pca_cv.best_score_)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best parameters:\")\n",
    "print(f\" - n_neighbors: {best_k}\")\n",
    "print(f\" - weights: {best_weight}\")\n",
    "print(f\" - metric: {best_metric}\")\n",
    "print(f\" - PCA components: {best_n_components}\")\n",
    "print(f\"RMSE (CV): {best_rmse_knn_pca:.2f}\")\n",
    "\n",
    "# 4. Evaluate best model separately using cross_val_score\n",
    "best_knn_pca_model = knn_pca_cv.best_estimator_\n",
    "\n",
    "mse_folds = -cross_val_score(\n",
    "    best_knn_pca_model, X, y,\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "mean_mse_knn_pca = mse_folds.mean()\n",
    "rmse_folds = np.sqrt(mse_folds)\n",
    "mean_rmse_knn_pca = np.sqrt(mean_mse_knn_pca)\n",
    "\n",
    "# Define MAE scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# MAE cross-validation\n",
    "mae_scores = -cross_val_score(\n",
    "    best_knn_pca_model, X, y,\n",
    "    cv=cv_strategy,\n",
    "    scoring=mae_scorer\n",
    ")\n",
    "mean_mae_knn_pca = mae_scores.mean()\n",
    "\n",
    "# Print detailed results\n",
    "print(\"\\nKNN Regression with PCA Cross-Validation Results:\\n\")\n",
    "print(f\"RMSE for each fold: {np.round(rmse_folds, 2)}\")\n",
    "print(f\"Mean RMSE: {mean_rmse_knn_pca:.2f} (±{rmse_folds.std():.2f})\\n\")\n",
    "\n",
    "print(f\"MSE for each fold: {np.round(mse_folds, 2)}\")\n",
    "print(f\"Mean MSE: {mean_mse_knn_pca:.2f} (±{mse_folds.std():.2f})\\n\")\n",
    "\n",
    "print(f\"MAE for each fold: {np.round(mae_scores, 2)}\")\n",
    "print(f\"Mean MAE: {mean_mae_knn_pca:.2f} (±{mae_scores.std():.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better performance can be observed when reducing dimensionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
